{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44ddad4e",
   "metadata": {},
   "source": [
    "# __Использованные материалы__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acffaa9",
   "metadata": {},
   "source": [
    "* [LightFM Github](https://github.com/lyst/lightfm)\n",
    "* [LightFM documentation](https://making.lyst.com/lightfm/docs/quickstart.html)\n",
    "* [Google recommendation systems course](https://developers.google.com/machine-learning/recommendation)\n",
    "* [Recommender system using Bayesian personalized ranking](https://towardsdatascience.com/recommender-system-using-bayesian-personalized-ranking-d30e98bba0b9)\n",
    "* [Learning to Rank Sketchfab Models with LightFM](https://www.ethanrosenthal.com/2016/11/07/implicit-mf-part-2/)\n",
    "* [How to build a Movie Recommender System in Python using LightFm](https://towardsdatascience.com/how-to-build-a-movie-recommender-system-in-python-using-lightfm-8fa49d7cbe3b)\n",
    "* [The Movies Dataset](https://www.kaggle.com/rounakbanik/the-movies-dataset/home?select=ratings_small.csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bcf4f4",
   "metadata": {},
   "source": [
    "# __Краткое введение__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2818c48b",
   "metadata": {},
   "source": [
    "__LightFM__ - это реализация на Python'е ряда популярных алгоритмов рекомендаций, включая эффективную реализацию BPR и WARP. Он прост в использовании, быстр (благодаря многопоточности) и дает высококачественные результаты. <br>\n",
    "Существуют две основные стратегии создания рекомендательных систем: \n",
    "* __Content-based Filtering__\n",
    "* __Collaborative filtering__\n",
    "\n",
    "На практике чаще всего они используются в совокупности.<br>\n",
    "<em>Далее для удобства будет использоваться термин item, который подразумевает под собой сущности, рекомендуемые системой.</em>\n",
    "\n",
    "### __Content-based Filtering__ \n",
    "Данный подход предполагает работу с метаданными пользователя, которые собираются различными способами:\n",
    "* __explicit__ - пользователь заполняет анкеты для выявление предпочтений, к примеру оценивает какой-то item по дифференцированной шкале.<br>\n",
    "* __implicit__ - все действия пользователя протоколируются для выявления предпочтений, к примеру переход по ссылками, информация о компьютере пользователя и тп.<br>\n",
    "\n",
    "### __Collaborative filtering__ \n",
    "Данный подход использует группировку пользователей и item'ов по каким-то сходствам/критериям. Будет реализоваться следующая логика \"Пользователям, которым понравился item $X$, также нравились item'ы $Y$\". Похожесть как правило определяется следующими методами:<br>\n",
    "* __Content-based__ - на основании характеристик item'ов и пользователей.<br>\n",
    "* __Transaction-based__ - на основании того, входили ли item'ы в одну транзакцию, а пользователи совершали схожие действия.<br>\n",
    "\n",
    "### Machine-learned ranking \n",
    "В __LightFM__ представлены два классических подхода MLR'а:\n",
    "* __Bayesian Personalized Ranking (BLR)__ \n",
    "* __Weighted Approximate-Rank Pairwise (WARP)__ \n",
    "\n",
    "### Bayesian Personalized Ranking \n",
    "Основная идея заключается в выборке и попарном сравнение положительных и отрицательных item'ов. Алгоритм в упрощенном виде можно представить следующим образом:\n",
    "1. Случайным образом возьмем пользователя $u$ и item $i$, который ранее был выбран пользователем, в таком случае item $i$ будет считаться <em>положительным.</em>\n",
    "2. Случайным образом возьмем item $j$, который был выбран пользователем <em>реже</em>, чем $i$ (в том числе, который пользователь никогда не выбирал), в таком случае item $j$ будет считаться <em>отрицательным.</em>\n",
    "3. Вычисляем оценку $p_{ui}$ и $p_{uj}$ пользователя $u$, а также положительного item'а $i$ и отрицательного item'а $j$ соответственно.\n",
    "4. Находим разницу между положительными и отрицательными оценками, как $x_{uij} = p_{ui} - p_{uj}.$ \n",
    "5. Пропускаем эту разницу через сигмоид и используем ее для вычисления веса для обновления всех параметров модели с помощью Stochastic gradient descent(SGD).\n",
    "\n",
    "### Weighted Approximate-Rank Pairwise\n",
    "Концепция данного подхода схожа с BPR, за исключением случаев, когда происходит SGD обновление:\n",
    "* В BPR SGD обновление происходит каждый раз с разницей в качестве веса.\n",
    "* WARP запускает SGD обновление только в случае неверного предсказания (т.е. оценка отрицательного item'а больше положительного). Если предсказание было верным, то продолжаем выбирать отрицательные item'ы, пока не получим неверный прогноз или не достигнем некоторого порогового значения.\n",
    "\n",
    "Для этих целей WARP предоставляет два гиперпараметра:\n",
    "1. __Margin__ - определяет насколько ошибочным должен быть прогноз для совершения SGD обновления. \n",
    "2. __Cutoff__ - определяет сколько раз мы готовы выбирать отрицательные примеры, пытаясь получить неверное предсказание, прежде чем откажемся и перейдем к следующему пользователю.\n",
    "\n",
    "<em>Автор статьи [Learning to Rank Sketchfab Models with LightFM](https://www.ethanrosenthal.com/2016/11/07/implicit-mf-part-2/) утверждает, что на практике вероятнее всего WARP предпочтительнее для большинства рекомендательных систем, нежели BPR.</em>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3425208c",
   "metadata": {},
   "source": [
    "# __Тестовый пример__\n",
    "Попробуем реализовать простейшую рекомендательную систему на основе [датасета, предоставляемого LightFM'ом.](https://grouplens.org/datasets/movielens/100k/)\n",
    "### __Установка зависимостей__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15e70821-e89a-4d7a-a8e3-4ed974090075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\python37\\lib\\site-packages (21.2.4)\n"
     ]
    }
   ],
   "source": [
    "!\"c:\\python37\\python.exe\" -m pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "755f45e4-834a-4925-8bd1-19d1448a3891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightfm\n",
      "  Using cached lightfm-1.16.tar.gz (310 kB)\n",
      "Requirement already satisfied: numpy in c:\\python37\\lib\\site-packages (from lightfm) (1.20.2)\n",
      "Requirement already satisfied: scipy>=0.17.0 in c:\\python37\\lib\\site-packages (from lightfm) (1.7.1)\n",
      "Requirement already satisfied: requests in c:\\python37\\lib\\site-packages (from lightfm) (2.25.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\python37\\lib\\site-packages (from lightfm) (0.24.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\python37\\lib\\site-packages (from requests->lightfm) (1.26.3)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\python37\\lib\\site-packages (from requests->lightfm) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python37\\lib\\site-packages (from requests->lightfm) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\python37\\lib\\site-packages (from requests->lightfm) (2.10)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\python37\\lib\\site-packages (from scikit-learn->lightfm) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\python37\\lib\\site-packages (from scikit-learn->lightfm) (2.2.0)\n",
      "Using legacy 'setup.py install' for lightfm, since package 'wheel' is not installed.\n",
      "Installing collected packages: lightfm\n",
      "    Running setup.py install for lightfm: started\n",
      "    Running setup.py install for lightfm: finished with status 'done'\n",
      "Successfully installed lightfm-1.16\n",
      "Collecting lightfm\n",
      "  Using cached lightfm-1.16.tar.gz (310 kB)\n",
      "Requirement already satisfied: numpy in c:\\python37\\lib\\site-packages (from lightfm) (1.20.2)\n",
      "Requirement already satisfied: scipy>=0.17.0 in c:\\python37\\lib\\site-packages (from lightfm) (1.7.1)\n",
      "Requirement already satisfied: requests in c:\\python37\\lib\\site-packages (from lightfm) (2.25.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\python37\\lib\\site-packages (from lightfm) (0.24.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python37\\lib\\site-packages (from requests->lightfm) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\python37\\lib\\site-packages (from requests->lightfm) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\python37\\lib\\site-packages (from requests->lightfm) (1.26.3)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\python37\\lib\\site-packages (from requests->lightfm) (4.0.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\python37\\lib\\site-packages (from scikit-learn->lightfm) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\python37\\lib\\site-packages (from scikit-learn->lightfm) (2.2.0)\n",
      "Using legacy 'setup.py install' for lightfm, since package 'wheel' is not installed.\n",
      "Installing collected packages: lightfm\n",
      "    Running setup.py install for lightfm: started\n",
      "    Running setup.py install for lightfm: finished with status 'done'\n",
      "Successfully installed lightfm-1.16\n"
     ]
    }
   ],
   "source": [
    "!pip install lightfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "740bbb3d-99a0-4de5-98b1-1038a4b862f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\python37\\lib\\site-packages (1.20.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12732564-66ba-4786-963a-45a1b1d6e305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy in c:\\python37\\lib\\site-packages (1.7.1)\n",
      "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in c:\\python37\\lib\\site-packages (from scipy) (1.20.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f7ccd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Импорт необходимых библиотек для тестового примера\n",
    "import numpy as np\n",
    "from lightfm.datasets import fetch_movielens #метод lightfm для извлечения данных фильма\n",
    "from lightfm import LightFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f6dc0096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<943x1682 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 49906 stored elements in COOrdinate format>\n",
      "<943x1682 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 5469 stored elements in COOrdinate format>\n"
     ]
    }
   ],
   "source": [
    "#Получаем данные фильма с минимальным рейтингом 4\n",
    "data = fetch_movielens(min_rating = 4.0)\n",
    "\n",
    "#Отобразим обучающий и тестовый набор\n",
    "print(repr(data['train']))\n",
    "print(repr(data['test']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "114aa879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 3\n",
      "     Known positives:\n",
      "        Seven (Se7en) (1995)\n",
      "        Contact (1997)\n",
      "        Starship Troopers (1997)\n",
      "     Recommended:\n",
      "        L.A. Confidential (1997)\n",
      "        Starship Troopers (1997)\n",
      "        Cop Land (1997)\n",
      "User 25\n",
      "     Known positives:\n",
      "        Dead Man Walking (1995)\n",
      "        Star Wars (1977)\n",
      "        Fargo (1996)\n",
      "     Recommended:\n",
      "        Fargo (1996)\n",
      "        English Patient, The (1996)\n",
      "        Contact (1997)\n",
      "User 451\n",
      "     Known positives:\n",
      "        Twelve Monkeys (1995)\n",
      "        Babe (1995)\n",
      "        Mr. Holland's Opus (1995)\n",
      "     Recommended:\n",
      "        Raiders of the Lost Ark (1981)\n",
      "        Amadeus (1984)\n",
      "        Sting, The (1973)\n"
     ]
    }
   ],
   "source": [
    "#Создадим модель\n",
    "model = LightFM(loss = 'warp')\n",
    "#Тренировка\n",
    "model.fit(data['train'], epochs=30, num_threads=2)\n",
    "\n",
    "#Рекомендательная функция\n",
    "def sample_recommendation(model, data, user_ids):\n",
    "    #Число пользователей и фильмов в обучающем наборе\n",
    "    n_users, n_items = data['train'].shape\n",
    "    for user_id in user_ids:\n",
    "    \t#Фильмы, которые уже понравились пользователям\n",
    "        known_positives = data['item_labels'][data['train'].tocsr()[user_id].indices]\n",
    "        #Предсказание фильмов, которые им понравится\n",
    "        scores = model.predict(user_id, np.arange(n_items))\n",
    "        #Сортирует результат по оценке\n",
    "        top_items = data['item_labels'][np.argsort(-scores)]\n",
    "        #Отображение результатов\n",
    "        print(\"User %s\" % user_id)\n",
    "        print(\"     Known positives:\")\n",
    "\n",
    "        for x in known_positives[:3]:\n",
    "            print(\"        %s\" % x)\n",
    "\n",
    "        print(\"     Recommended:\")\n",
    "\n",
    "        for x in top_items[:3]:\n",
    "            print(\"        %s\" % x)\n",
    "            \n",
    "sample_recommendation(model, data, [3, 25, 451])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797024bd",
   "metadata": {},
   "source": [
    "## __Тестовый пример__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
